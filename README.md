MatchMakerÂ AI â€” v2 Roadmap (OrdreÂ 66)

âœ¨Â VisionÂ & ButÂ initial

MatchMakerÂ AI connecteâ€¯:

Associations (besoins, projets, Ã©vÃ©nements)

Entreprises (dons matÃ©riels, compÃ©tences, mÃ©cÃ©nat)

ExempleÂ : un club basket Ã©critÂ : Â«â€¯On cherche des ballons de basket â€“ besoin urgent â€“ 34090â€¯Â».

Lâ€™API renvoieÂ :

[
  {"enseigne":"Intersport Montpellier","commune":"34090","score":0.93},
  {"enseigne":"DÃ©cathlonÂ Pro","commune":"34740","score":0.91},
  {"enseigne":"Recyc'Sport","commune":"34000","score":0.87}
]

Aucune entreprise nâ€™a explicitement Ã©crit Â«â€¯je donne des ballonsâ€¯Â», mais le moteur sÃ©mantique comprend lâ€™affinitÃ©.

ğŸ“œÂ Historique rapide

Ã‰tape

â€¯Contenu

â€¯Statut

v1

Â Nettoyage CSVÂ â†’â€¯Parquet, Jaccard/TFâ€‘IDF, LightGBM de base

âœ…Â Fonctionnel (RAM ~8â€¯Go)

OrdreÂ 66

Â Prouve quâ€™on peut matcher sans gros moyens

âœ…

v2 (en cours)

Â Embeddings MiniLMÂ +â€¯index FAISS, reâ€‘ranking LightGBM, API FastAPI

ğŸš§

v3 (plus tard)

Â Crossâ€‘encoder, feedback utilisateur, fineâ€‘tuning

ğŸ”®

ğŸ—ï¸Â Architecture v2 proposÃ©e

matchmaker_ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI
â”‚   â”‚   â”œâ”€â”€ api/v1/endpoints/  # /match, /health
â”‚   â”‚   â”œâ”€â”€ services/          # match_service.py
â”‚   â”‚   â”œâ”€â”€ models/            # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ core/              # config, logging
â”‚   â”‚   â””â”€â”€ db/                # loaders (FAISS, parquet)
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/       # zips tÃ©lÃ©chargÃ©s
â”‚   â”œâ”€â”€ interim/   # full.parquet
â”‚   â”œâ”€â”€ processed/ # *_clean.parquet
â”‚   â”œâ”€â”€ indexes/   # faiss index & npy
â”‚   â””â”€â”€ samples/   # petits jeux jouet
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ embed_and_index.py  # â†’Â FAISS
â”‚   â”œâ”€â”€ train_reranker.py   # LightGBM sur pairs*
â”‚   â””â”€â”€ demo_query.py       # requÃªte locale
â”œâ”€â”€ templates/              # html Jinja2 (optionnel)
â””â”€â”€ static/                 # css, js, images

ğŸ”¬Â Pipeline v2 dÃ©taillÃ©

Phase

Script

â€¯Sortie

Â Notes

â¡ï¸ 0. PrÃ©â€‘requis

pip install -r requirements.txt

â€“

faissâ€‘cpu, sentenceâ€‘transformers, lightgbm, fastapi, uvicorn

1. Embeddings

scripts/embed_and_index.py

data/indexes/{rna,sirene}.index + .npy

batch 50â€¯k, MiniLM (384â€¯d)

2. Rerank

scripts/train_reranker.py

data/model/reranker.joblib

uses cosine, len_diff, CP_proximity

3. API

uvicorn backend.app.main:app --reload

Swagger at /docs

endpoint POST /match

ğŸš€Â RunÂ de test (toy)

python scripts/demo_query.py \
  --texte "ballons basket" \
  --cp 34090 \
  --top 5

RetourÂ :

[
  {"enseigne":"Intersport Montpellier","distance":0.07},
  {"enseigne":"DÃ©cathlonÂ Pro","distance":0.09},
  ...
]

ğŸ“ˆÂ Roadmap condensÃ©e



Feedback bienvenuÂ !



ğŸ“ Fichier crÃ©Ã©
Nom du script	Chemin	RÃ´le
embed_and_index.py	matchmaker_ai/scripts/embed_and_index.py	Embedding + indexation FAISS des bases RNA et SIRENE

ğŸ§  Comment Ã§a marche ? DÃ©tail du code
1. Chargement par morceaux (batches)
Le code lit les fichiers rna_clean.parquet et sirene_clean.parquet par tranche (ex: 5000 lignes) pour Ã©viter de charger toute la RAM.

2. Embeddings
On utilise MiniLM (via sentence-transformers) pour transformer chaque texte (ligne) en vecteur dense de 384 dimensions :

python
Copier le code
from sentence_transformers import SentenceTransformer
model = SentenceTransformer("all-MiniLM-L6-v2")
vectors = model.encode(list_of_texts, show_progress_bar=True)


1